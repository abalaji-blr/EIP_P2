{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenTextWithLSTM_v4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JRxLcwayV_v-",
        "hIXDuGYl9uFz",
        "Ux50so8tTeBx",
        "aGJb7L_MiuNh"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abalaji-blr/EIP_P2/blob/master/GenTextWithLSTM_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Yih_zZqavd",
        "colab_type": "text"
      },
      "source": [
        "# Generate Text With LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0h5Wyt6rAt6",
        "colab_type": "text"
      },
      "source": [
        "**Objective:**\n",
        "  * First, learn the sequence of characters from the book - Alice's Adventure in Wonderland.\n",
        "  * Second, generate new text based on the learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKhabt08qqwl",
        "colab_type": "text"
      },
      "source": [
        "## Develop model to learn sequence of characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssWF9LxstYPU",
        "colab_type": "text"
      },
      "source": [
        "Use the sequence of characters from the book - *Alice's Adventure in Wonderland*. The text version of book can be downloaded from **[Project Gutenberg](http://www.gutenberg.org/cache/epub/11/pg11.txt)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_19H41GtRpv",
        "colab_type": "text"
      },
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJi-w8PToC20",
        "colab_type": "code",
        "outputId": "f584f83d-0dcc-4b20-a258-6bf365aa36e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrHhMmkGuhTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !cp '/content/gdrive/My Drive/App/EIP_Phase2/AliceInWonderland.txt' /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5VvJPPAvhLj",
        "colab_type": "code",
        "outputId": "b0327364-8f7f-429a-fe98-ee6492feea67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfBTtkk2wKkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"/content/AliceInWonderland.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEyRNUWJwEro",
        "colab_type": "code",
        "outputId": "561783fd-f227-4b69-9486-51504902301f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -l $filename"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 147739 Jul 25 06:56 /content/AliceInWonderland.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ag7KiyyvlRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RM2QKGD-5a3",
        "colab_type": "code",
        "outputId": "b9f48199-8aad-4bda-d6d2-4e9214148800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "raw_text[0:500]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"alice's adventures in wonderland\\n\\nlewis carroll\\n\\nthe millennium fulcrum edition 3.0\\n\\nchapter i. down the rabbit-hole\\n\\nalice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought alice 'without pictures or\\nconversations?'\\n\\nso she was considering in her own mind (as well as she could, for the\\nhot day \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpd0wWYxAwFf",
        "colab_type": "text"
      },
      "source": [
        "### Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXR38HPz_w5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSji9EtP_pSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#?raw_text.translate\n",
        "?str.maketrans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lonTBHr9YSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove all punctation from the source text\n",
        "# maketrans - builds a mapping table used by str.translate\n",
        "#   when thrid arg present in maketrans(), those characters will be mapped to\n",
        "#   None in the result.\n",
        "trans_text = raw_text.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upms1-YsAkB9",
        "colab_type": "code",
        "outputId": "0b43ec58-28fe-4ad1-b0e3-72f7798b271a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "trans_text[0:500]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alices adventures in wonderland\\n\\nlewis carroll\\n\\nthe millennium fulcrum edition 30\\n\\nchapter i down the rabbithole\\n\\nalice was beginning to get very tired of sitting by her sister on the\\nbank and of having nothing to do once or twice she had peeped into the\\nbook her sister was reading but it had no pictures or conversations in\\nit and what is the use of a book thought alice without pictures or\\nconversations\\n\\nso she was considering in her own mind as well as she could for the\\nhot day made her feel ve'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um1CSxXDIZEr",
        "colab_type": "text"
      },
      "source": [
        "### Build Dictionaries for mapping input charas to integer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeovdOvDwbIi",
        "colab_type": "code",
        "outputId": "6f0d089e-7a10-4be4-cabb-b5af114eec13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "chars = sorted(list(set(trans_text)))  # get unique chars, so use set\n",
        "print(chars)\n",
        "print(len(chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '0', '3', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziYj7AHKIqd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict( (i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46IWRQI_MLYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_string(arr_int):\n",
        "  str = ''.join([int_to_char[c] for c in arr_int])\n",
        "  return(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Y682Iqwq4F",
        "colab_type": "code",
        "outputId": "4b3fcada-0d7e-4baf-fcb9-55495bb49726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(trans_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  136085\n",
            "Total Vocab:  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Arb4B5eDbkP",
        "colab_type": "text"
      },
      "source": [
        "### Build dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nXo1p8oFZOO",
        "colab_type": "text"
      },
      "source": [
        "To build dataset, use the following steps:\n",
        "  * To mimic variable length input, try **sliding window of variable length**\n",
        "  * In the case of variable length input, use pad_sequences.\n",
        "  * Pad in the front/back (pre/post), experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBdYClu1KlLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's start with fixed length\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtxRgdYDKuWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  # get the input and expected output (next char)\n",
        "  seq_in = trans_text[i:i+seq_length]\n",
        "  seq_out = trans_text[i+seq_length]\n",
        "  \n",
        "  # gen. dataset\n",
        "  # note instead of chars, it has to be integers, use populated dictionary.\n",
        "  dataX.append([char_to_int[c] for c in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "  \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA5ZJJQAtGgy",
        "colab_type": "text"
      },
      "source": [
        "### Use variable sliding window to mimic variable length input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8geyPyO6hXWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use variable sliding window to mimic variable length input\n",
        "total = 0\n",
        "cnt = 0\n",
        "max_len = n_chars - seq_length\n",
        "while (cnt < max_len):\n",
        "  # generate variable length from 80 thru 100\n",
        "  num = numpy.random.randint(80,100)\n",
        "  #print('num:', num)\n",
        "  if ( cnt + num > max_len ):\n",
        "    break\n",
        "    \n",
        "  # create the training input and output\n",
        "  seq_in = trans_text[cnt:cnt+num]\n",
        "  seq_out = trans_text[cnt+num]\n",
        "  \n",
        "  #gen dataset\n",
        "  # note: input should be int instead of chars, use dictionary\n",
        "  dataX.append([char_to_int[c] for c in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "  \n",
        "  total += num\n",
        "  #print(total)\n",
        "  cnt += 1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSvDffdDLvIY",
        "colab_type": "code",
        "outputId": "504b5ec4-ba01-4ba7-aad7-a9a1593171a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n_patterns = len(dataX)\n",
        "print(n_patterns)\n",
        "len(dataX) == len(dataY)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "135896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmXYThOUL-VZ",
        "colab_type": "code",
        "outputId": "ac230e1e-235c-4956-abbf-ae6bb40126d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(get_string(dataX[5]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s adventures in wonderland\n",
            "\n",
            "lewis carroll\n",
            "\n",
            "the millennium fulcrum edition 30\n",
            "\n",
            "chapter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkMnSKKL8xf1",
        "colab_type": "code",
        "outputId": "e71354b2-b723-418d-a959-f4ed5516dc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(get_string(dataX[6]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " adventures in wonderland\n",
            "\n",
            "lewis carroll\n",
            "\n",
            "the millennium fulcrum edition 30\n",
            "\n",
            "chapter i d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzZhPed8u07E",
        "colab_type": "code",
        "outputId": "1c8c31b5-22d7-469e-907d-b2efbdf81072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(int_to_char[dataY[5]])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SbtMaBHNke9",
        "colab_type": "code",
        "outputId": "462db11f-0c63-43a5-8ef9-154dc9f5b5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(get_string(dataX[100]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e rabbithole\n",
            "\n",
            "alice was beginning to get very tired of sitting by her sister on the\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZj1sI9jvHGY",
        "colab_type": "code",
        "outputId": "5d7d1e12-7c70-40a3-c244-6c5c78dc81dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(int_to_char[dataY[100]])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddDQW2-yTmsf",
        "colab_type": "text"
      },
      "source": [
        "### Handle variable length input using pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4XJLFA5TrYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrzkI9eT-3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bkJopryTy7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad at the front side as we are predicting the next character and trainY has next character\n",
        "dataX_pad = pad_sequences(dataX, maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMzIkxV_h2GW",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data for LSTM\n",
        "\n",
        "* LSTM expects the data in [samples, time_steps, features]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6qh3v5eiWwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?numpy.reshape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6OBdc7oh1uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data, new-shape (num_samples = len(dataX_pad)), maxlen=100, num_featurs = 1\n",
        "trainX = numpy.reshape(dataX_pad, (len(dataX_pad), 100, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRMFSlPMi-g3",
        "colab_type": "code",
        "outputId": "86177e47-c3bb-4365-8881-6e43004d1e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135896, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BhQ_ek0jHeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize the data, convert the data in the range 0 to 1, as sigmoid activation function is used by default\n",
        "trainX = trainX / float(n_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0qt_Go3jKGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trainX[6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EtVfa4We6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode the output variable\n",
        "trainY = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ98RKnRWzxs",
        "colab_type": "code",
        "outputId": "5c8c7750-d9fd-4a6f-8f43-e418e96577ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(trainY))\n",
        "print(len(trainY[0]))\n",
        "print(trainY[0])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "135896\n",
            "30\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JtKK8FMXLie",
        "colab_type": "code",
        "outputId": "2c908e46-fa1f-4b82-82d2-1e50016cbdcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135896, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhfUCHcvkT6A",
        "colab_type": "code",
        "outputId": "f5f0d9d0-b779-416f-c2ef-5a67b793cc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135896, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRxLcwayV_v-",
        "colab_type": "text"
      },
      "source": [
        "### Build Model using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAGvYve5Ypyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHaZuXULWC47",
        "colab_type": "code",
        "outputId": "08b22276-bc12-4689-8e6f-fbe5a08ef056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "# dropout 10 percent of inputs to LSTM\n",
        "model.add(LSTM(256, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True, dropout=0.1))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(trainY.shape[1], activation='softmax'))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 08:05:59.250150 139779465680768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 08:05:59.300413 139779465680768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 08:05:59.307514 139779465680768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 08:05:59.542425 139779465680768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0725 08:05:59.560908 139779465680768 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixk9H3vmlVws",
        "colab_type": "code",
        "outputId": "a0dabb08-6988-4b7f-d2e0-7a844f261ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 08:06:05.395848 139779465680768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0725 08:06:05.429776 139779465680768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWjVwqhglXR7",
        "colab_type": "code",
        "outputId": "ade3520c-8f18-4459-ba33-ee6c19b2f61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                7710      \n",
            "=================================================================\n",
            "Total params: 797,214\n",
            "Trainable params: 797,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9MPVCBrkoox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"best_weights_vl_v4.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts7FluEOk24d",
        "colab_type": "code",
        "outputId": "3125e4ed-a384-4f34-d3d6-564b76c09f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, epochs=20, batch_size=512, callbacks=callbacks_list)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 08:07:06.575146 139779465680768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "135896/135896 [==============================] - 146s 1ms/step - loss: 2.8858\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.88584, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 2/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 2.7642\n",
            "\n",
            "Epoch 00002: loss improved from 2.88584 to 2.76416, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 3/20\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 2.5502\n",
            "\n",
            "Epoch 00003: loss improved from 2.76416 to 2.55015, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 4/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 2.3830\n",
            "\n",
            "Epoch 00004: loss improved from 2.55015 to 2.38302, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 5/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 2.2551\n",
            "\n",
            "Epoch 00005: loss improved from 2.38302 to 2.25508, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 6/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 2.1482\n",
            "\n",
            "Epoch 00006: loss improved from 2.25508 to 2.14821, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 7/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 2.0590\n",
            "\n",
            "Epoch 00007: loss improved from 2.14821 to 2.05899, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 8/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.9797\n",
            "\n",
            "Epoch 00008: loss improved from 2.05899 to 1.97967, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 9/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.9106\n",
            "\n",
            "Epoch 00009: loss improved from 1.97967 to 1.91061, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 10/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.8484\n",
            "\n",
            "Epoch 00010: loss improved from 1.91061 to 1.84838, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 11/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.7879\n",
            "\n",
            "Epoch 00011: loss improved from 1.84838 to 1.78789, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 12/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.7336\n",
            "\n",
            "Epoch 00012: loss improved from 1.78789 to 1.73358, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 13/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.6803\n",
            "\n",
            "Epoch 00013: loss improved from 1.73358 to 1.68026, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 14/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.6321\n",
            "\n",
            "Epoch 00014: loss improved from 1.68026 to 1.63208, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 15/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.5847\n",
            "\n",
            "Epoch 00015: loss improved from 1.63208 to 1.58471, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 16/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.5403\n",
            "\n",
            "Epoch 00016: loss improved from 1.58471 to 1.54029, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 17/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.4913\n",
            "\n",
            "Epoch 00017: loss improved from 1.54029 to 1.49130, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 18/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.4417\n",
            "\n",
            "Epoch 00018: loss improved from 1.49130 to 1.44173, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 19/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.3995\n",
            "\n",
            "Epoch 00019: loss improved from 1.44173 to 1.39947, saving model to best_weights_vl_v4.hdf5\n",
            "Epoch 20/20\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.3543\n",
            "\n",
            "Epoch 00020: loss improved from 1.39947 to 1.35434, saving model to best_weights_vl_v4.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20a29a77f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8m0WmXAe9CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/best_weights_vl_v4.hdf5 '/content/gdrive/My Drive/App/EIP_Phase2/lstm_vl_v4.hdf5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIXDuGYl9uFz",
        "colab_type": "text"
      },
      "source": [
        "### Train 30 more epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojA8UzqfW8wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath2=\"/content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\"\n",
        "checkpoint2 = ModelCheckpoint(filepath2, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list2 = [checkpoint2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U90uMleXIYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?model.fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU4U2zVY9tDy",
        "colab_type": "code",
        "outputId": "edda07f0-b668-444d-9a9f-19ca40bcf33e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "H2 = model.fit(trainX, trainY, epochs=50, initial_epoch = 20, batch_size=512, callbacks=callbacks_list2)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.1790\n",
            "\n",
            "Epoch 00021: loss improved from inf to 1.17898, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 22/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.1336\n",
            "\n",
            "Epoch 00022: loss improved from 1.17898 to 1.13363, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 23/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.0878\n",
            "\n",
            "Epoch 00023: loss improved from 1.13363 to 1.08777, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 24/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.0442\n",
            "\n",
            "Epoch 00024: loss improved from 1.08777 to 1.04423, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 25/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 1.0051\n",
            "\n",
            "Epoch 00025: loss improved from 1.04423 to 1.00513, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 26/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.9639\n",
            "\n",
            "Epoch 00026: loss improved from 1.00513 to 0.96385, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 27/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.9256\n",
            "\n",
            "Epoch 00027: loss improved from 0.96385 to 0.92561, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 28/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.8824\n",
            "\n",
            "Epoch 00028: loss improved from 0.92561 to 0.88238, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 29/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.8440\n",
            "\n",
            "Epoch 00029: loss improved from 0.88238 to 0.84395, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 30/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.8112\n",
            "\n",
            "Epoch 00030: loss improved from 0.84395 to 0.81124, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 31/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.7753\n",
            "\n",
            "Epoch 00031: loss improved from 0.81124 to 0.77526, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 32/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.7471\n",
            "\n",
            "Epoch 00032: loss improved from 0.77526 to 0.74709, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 33/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.7157\n",
            "\n",
            "Epoch 00033: loss improved from 0.74709 to 0.71568, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 34/50\n",
            "135896/135896 [==============================] - 143s 1ms/step - loss: 0.6831\n",
            "\n",
            "Epoch 00034: loss improved from 0.71568 to 0.68312, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 35/50\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.6556\n",
            "\n",
            "Epoch 00035: loss improved from 0.68312 to 0.65564, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 36/50\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.6324\n",
            "\n",
            "Epoch 00036: loss improved from 0.65564 to 0.63245, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 37/50\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.6050\n",
            "\n",
            "Epoch 00037: loss improved from 0.63245 to 0.60502, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 38/50\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.5825\n",
            "\n",
            "Epoch 00038: loss improved from 0.60502 to 0.58250, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 39/50\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.5596\n",
            "\n",
            "Epoch 00039: loss improved from 0.58250 to 0.55959, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 40/50\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.5345\n",
            "\n",
            "Epoch 00040: loss improved from 0.55959 to 0.53454, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 41/50\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.5213\n",
            "\n",
            "Epoch 00041: loss improved from 0.53454 to 0.52126, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 42/50\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.5018\n",
            "\n",
            "Epoch 00042: loss improved from 0.52126 to 0.50183, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 43/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.4830\n",
            "\n",
            "Epoch 00043: loss improved from 0.50183 to 0.48296, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 44/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.4635\n",
            "\n",
            "Epoch 00044: loss improved from 0.48296 to 0.46346, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 45/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.4503\n",
            "\n",
            "Epoch 00045: loss improved from 0.46346 to 0.45029, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 46/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.4345\n",
            "\n",
            "Epoch 00046: loss improved from 0.45029 to 0.43454, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 47/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.4263\n",
            "\n",
            "Epoch 00047: loss improved from 0.43454 to 0.42635, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 48/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.4128\n",
            "\n",
            "Epoch 00048: loss improved from 0.42635 to 0.41275, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 49/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3980\n",
            "\n",
            "Epoch 00049: loss improved from 0.41275 to 0.39802, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n",
            "Epoch 50/50\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3895\n",
            "\n",
            "Epoch 00050: loss improved from 0.39802 to 0.38946, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t2_plus.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux50so8tTeBx",
        "colab_type": "text"
      },
      "source": [
        "### Train some more - Epochs 51 thru 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbkIKeCdTlyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath3=\"/content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\"\n",
        "checkpoint3 = ModelCheckpoint(filepath3, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list3 = [checkpoint3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgfbODSpTkq6",
        "colab_type": "code",
        "outputId": "936e8f39-1538-42a0-bd32-2f7df6fd6178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "H3 = model.fit(trainX, trainY, epochs=80, initial_epoch=50, batch_size=512, callbacks=callbacks_list3)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 51/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3743\n",
            "\n",
            "Epoch 00051: loss improved from inf to 0.37426, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 52/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3648\n",
            "\n",
            "Epoch 00052: loss improved from 0.37426 to 0.36476, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 53/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3703\n",
            "\n",
            "Epoch 00053: loss did not improve from 0.36476\n",
            "Epoch 54/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3427\n",
            "\n",
            "Epoch 00054: loss improved from 0.36476 to 0.34272, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 55/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3386\n",
            "\n",
            "Epoch 00055: loss improved from 0.34272 to 0.33860, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 56/80\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.3308\n",
            "\n",
            "Epoch 00056: loss improved from 0.33860 to 0.33079, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 57/80\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.3280\n",
            "\n",
            "Epoch 00057: loss improved from 0.33079 to 0.32803, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 58/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.3170\n",
            "\n",
            "Epoch 00058: loss improved from 0.32803 to 0.31700, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 59/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.3146\n",
            "\n",
            "Epoch 00059: loss improved from 0.31700 to 0.31460, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 60/80\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.3094\n",
            "\n",
            "Epoch 00060: loss improved from 0.31460 to 0.30936, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 61/80\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.3118\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.30936\n",
            "Epoch 62/80\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.3042\n",
            "\n",
            "Epoch 00062: loss improved from 0.30936 to 0.30417, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 63/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2938\n",
            "\n",
            "Epoch 00063: loss improved from 0.30417 to 0.29384, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 64/80\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.2887\n",
            "\n",
            "Epoch 00064: loss improved from 0.29384 to 0.28868, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 65/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2907\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.28868\n",
            "Epoch 66/80\n",
            "135896/135896 [==============================] - 140s 1ms/step - loss: 0.2942\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.28868\n",
            "Epoch 67/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.2755\n",
            "\n",
            "Epoch 00067: loss improved from 0.28868 to 0.27551, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 68/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.2757\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.27551\n",
            "Epoch 69/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.2781\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.27551\n",
            "Epoch 70/80\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3009\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.27551\n",
            "Epoch 71/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2804\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.27551\n",
            "Epoch 72/80\n",
            "135896/135896 [==============================] - 139s 1ms/step - loss: 0.2507\n",
            "\n",
            "Epoch 00072: loss improved from 0.27551 to 0.25073, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 73/80\n",
            "135896/135896 [==============================] - 139s 1ms/step - loss: 0.2307\n",
            "\n",
            "Epoch 00073: loss improved from 0.25073 to 0.23072, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 74/80\n",
            "135896/135896 [==============================] - 139s 1ms/step - loss: 0.2421\n",
            "\n",
            "Epoch 00074: loss did not improve from 0.23072\n",
            "Epoch 75/80\n",
            "135896/135896 [==============================] - 139s 1ms/step - loss: 0.3253\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.23072\n",
            "Epoch 76/80\n",
            "135896/135896 [==============================] - 139s 1ms/step - loss: 0.3376\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.23072\n",
            "Epoch 77/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2583\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.23072\n",
            "Epoch 78/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2260\n",
            "\n",
            "Epoch 00078: loss improved from 0.23072 to 0.22599, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 79/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2123\n",
            "\n",
            "Epoch 00079: loss improved from 0.22599 to 0.21231, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n",
            "Epoch 80/80\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2037\n",
            "\n",
            "Epoch 00080: loss improved from 0.21231 to 0.20368, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t3.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGJb7L_MiuNh",
        "colab_type": "text"
      },
      "source": [
        "### Training Epochs 80 thru 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IteU3OK7i13v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath4=\"/content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t4.hdf5\"\n",
        "checkpoint4 = ModelCheckpoint(filepath4, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list4 = [checkpoint4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY4k4p86jCs5",
        "colab_type": "code",
        "outputId": "b7db610d-c872-45af-b9b8-541c1f1d3b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "H4 = model.fit(trainX, trainY, epochs=100, initial_epoch=80, batch_size=512, callbacks=callbacks_list4)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 81/100\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.2022\n",
            "\n",
            "Epoch 00081: loss improved from inf to 0.20215, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t4.hdf5\n",
            "Epoch 82/100\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.2103\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.20215\n",
            "Epoch 83/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.5401\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.20215\n",
            "Epoch 84/100\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.3703\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.20215\n",
            "Epoch 85/100\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.2440\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.20215\n",
            "Epoch 86/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2115\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.20215\n",
            "Epoch 87/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2029\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.20215\n",
            "Epoch 88/100\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.1915\n",
            "\n",
            "Epoch 00088: loss improved from 0.20215 to 0.19148, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t4.hdf5\n",
            "Epoch 89/100\n",
            "135896/135896 [==============================] - 142s 1ms/step - loss: 0.1919\n",
            "\n",
            "Epoch 00089: loss did not improve from 0.19148\n",
            "Epoch 90/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.1938\n",
            "\n",
            "Epoch 00090: loss did not improve from 0.19148\n",
            "Epoch 91/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.1912\n",
            "\n",
            "Epoch 00091: loss improved from 0.19148 to 0.19119, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t4.hdf5\n",
            "Epoch 92/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.3903\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.19119\n",
            "Epoch 93/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.5678\n",
            "\n",
            "Epoch 00093: loss did not improve from 0.19119\n",
            "Epoch 94/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2798\n",
            "\n",
            "Epoch 00094: loss did not improve from 0.19119\n",
            "Epoch 95/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2228\n",
            "\n",
            "Epoch 00095: loss did not improve from 0.19119\n",
            "Epoch 96/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.2024\n",
            "\n",
            "Epoch 00096: loss did not improve from 0.19119\n",
            "Epoch 97/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.1941\n",
            "\n",
            "Epoch 00097: loss did not improve from 0.19119\n",
            "Epoch 98/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.1883\n",
            "\n",
            "Epoch 00098: loss improved from 0.19119 to 0.18830, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t4.hdf5\n",
            "Epoch 99/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.1861\n",
            "\n",
            "Epoch 00099: loss improved from 0.18830 to 0.18607, saving model to /content/gdrive/My Drive/App/EIP_Phase2/lstm_weights_vl_v4_t4.hdf5\n",
            "Epoch 100/100\n",
            "135896/135896 [==============================] - 141s 1ms/step - loss: 0.1900\n",
            "\n",
            "Epoch 00100: loss did not improve from 0.18607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26kvhpN_qYN0",
        "colab_type": "text"
      },
      "source": [
        "## Generate new sequence of characters from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XywFYYdq-Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load weights file\n",
        "#filename = \"best_weights.hdf5\"\n",
        "#model.load_weights(filename)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cig5Necio8Sa",
        "colab_type": "code",
        "outputId": "9e319ca1-49d9-4975-d4ee-2bf82b15d5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(trainX.shape)\n",
        "print(len(trainX))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135896, 100, 1)\n",
            "135896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60CSSDpDr9kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4baVPB69QDW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_prediction(prediction):\n",
        "  X = prediction[0] # sum(X) is approx 1\n",
        "  rnd_idx = numpy.random.choice(len(X), p=X)\n",
        "  return rnd_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtlzeOEuQ1c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_next_500_chars_with_sample_prediction(seed_str):\n",
        "  pattern = list(seed_str)\n",
        "  result_str = ''\n",
        "  for i in range(0,500):\n",
        "    # for predict, seed the initial pattern\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "  \n",
        "    #predict new char\n",
        "    pred = model.predict(x, verbose=0)\n",
        "  \n",
        "    #index = numpy.argmax(pred)\n",
        "    index = sample_prediction(pred)\n",
        "    new_char = int_to_char[index]\n",
        "  \n",
        "    #output the new char\n",
        "    sys.stdout.write(new_char)\n",
        "    result_str += new_char\n",
        "  \n",
        "    #update the input sequence to the model by eliminating the first character and\n",
        "    #appending the new char.\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "  \n",
        "  return result_str\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdix4U6ebCDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate next 500 characters\n",
        "def get_next_500_chars(seed_str):\n",
        "  pattern = seed_str\n",
        "  result_str = ''\n",
        "  for i in range(0,500):\n",
        "    # for predict, seed the initial pattern\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "  \n",
        "    #predict new char\n",
        "    pred = model.predict(x, verbose=0)\n",
        "  \n",
        "    index = numpy.argmax(pred)\n",
        "    new_char = int_to_char[index]\n",
        "  \n",
        "    #output the new char\n",
        "    sys.stdout.write(new_char)\n",
        "    result_str += new_char\n",
        "  \n",
        "    #update the input sequence to the model by eliminating the first character and\n",
        "    #appending the new char.\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "  \n",
        "  return result_str\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPVDGRBJnUBt",
        "colab_type": "code",
        "outputId": "1d3ac270-5184-4a73-d342-849078eaa645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# to predict, we need to seed the model with past history, in our case, text pattern.\n",
        "# pick one text pattern from the corpse\n",
        "seed = numpy.random.randint(0, len(trainX)-1)\n",
        "pattern = list(dataX_pad[seed])\n",
        "\n",
        "print(len(pattern))\n",
        "print('Seed:', get_string(pattern))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "Seed: \n",
            "\n",
            "\n",
            "\n",
            "hroom said the caterpillar just as if she had asked it\n",
            "aloud and in another moment it was out of\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiS79tq8fxCb",
        "colab_type": "code",
        "outputId": "702d9b70-0cbc-4c91-e302-c080f3fb412d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# predict\n",
        "res_str = get_next_500_chars(pattern)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " thg way \n",
            "teryargf of uhe whore celtr sas re like\n",
            "\n",
            "htude herele of her on\n",
            "the way alice teptle hir hear\n",
            "ii i vaid tig dackeed the wo blice \n",
            "vole so the soor the hou tomet of the helert wert inr sarder it whe sighcoddeytryle \n",
            "shersesp of the hear of oert ard\n",
            "the ltrker thall her in thaml tie whole pifelng sut it wurn thment forbidcr\n",
            "the waid to her erceped to tuch where when anl herching to hersenf io ins bitaid bnice pood\n",
            "\n",
            "whe qock turtle noatdh and nrsking\n",
            "ang then a great murtyed tng fonv bprt"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-HVEV5Vp86q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6650be4b-add0-43c4-941b-4c84bd124f78"
      },
      "source": [
        "print('Seed:', get_string(dataX_pad[750]))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " think it so\n",
            "very much out of the way to hear the rabbit say to itself oh dear\n",
            "oh dear i sha\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XruvHMy5qHah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3fcb887e-a8fc-4b23-c83e-bc6d969e20a3"
      },
      "source": [
        "pattern2 = list(dataX_pad[750])\n",
        "get_next_500_chars(pattern2)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ll oevs\n",
            "alice repelbered sogecsry all hu anloe so oertonnn toeerhe\n",
            "autty alice tone\n",
            "uhme tog waid to herchnch\n",
            "sror the wuoue dowl dowahes to lerpen thal and a little het oe whem oistle rebnly thamln oersronn anice hed ltog het wonce sff lntd\n",
            "anice vepled puerened out \n",
            "theye waid th pef and hor soment alice cuppeutiog togrieed it arxious fownd thapled at lepprr and taid to the helt brneuuing\n",
            "\n",
            "fagf of tame gld to the beardeslt far fow tome\n",
            "th puce sffncod anice\n",
            "and ooe fiit waid the whisg wases el"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ll oevs\\nalice repelbered sogecsry all hu anloe so oertonnn toeerhe\\nautty alice tone\\nuhme tog waid to herchnch\\nsror the wuoue dowl dowahes to lerpen thal and a little het oe whem oistle rebnly thamln oersronn anice hed ltog het wonce sff lntd\\nanice vepled puerened out \\ntheye waid th pef and hor soment alice cuppeutiog togrieed it arxious fownd thapled at lepprr and taid to the helt brneuuing\\n\\nfagf of tame gld to the beardeslt far fow tome\\nth puce sffncod anice\\nand ooe fiit waid the whisg wases el'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VtbFrJVqPjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d568c712-5f5c-46f9-ca8d-0e62f1d0a26e"
      },
      "source": [
        "pattern2 = list(dataX_pad[750])\n",
        "get_next_500_chars_with_sample_prediction(pattern2)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ll oevs\n",
            "alice reptle his waid the whilgd tuiee hardlpg togeply wald whe ooment\n",
            "soease when tuch a heml oftsock cnd jeel io surtess\n",
            "\n",
            "whats \n",
            "io rometwine tolest\n",
            "sh soeacle\n",
            "au again to peaveny \n",
            "goot gitier io a   wogacing onth tiami b good a cuckn someth cack ol the ltscfoet ehggiedt clice qut whe whi boom tuat ttt atd toment soead\n",
            "cewserfrl tmment atd fombhd ruize eolking oo uhe sasty sww at sruse stam anice comsaler eottldirsates apd mersonns\n",
            "anice qextoef dowi cnntercrlamistlng to her hftter thn"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ll oevs\\nalice reptle his waid the whilgd tuiee hardlpg togeply wald whe ooment\\nsoease when tuch a heml oftsock cnd jeel io surtess\\n\\nwhats \\nio rometwine tolest\\nsh soeacle\\nau again to peaveny \\ngoot gitier io a   wogacing onth tiami b good a cuckn someth cack ol the ltscfoet ehggiedt clice qut whe whi boom tuat ttt atd toment soead\\ncewserfrl tmment atd fombhd ruize eolking oo uhe sasty sww at sruse stam anice comsaler eottldirsates apd mersonns\\nanice qextoef dowi cnntercrlamistlng to her hftter thn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdm3TFprHYS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}